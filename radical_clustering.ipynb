{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5e52ea-955e-4807-bb14-3bd02de51587",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "from dataclasses import dataclass\n",
    "from typing import Final\n",
    "\n",
    "import IPython\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from PIL import Image, ImageFilter\n",
    "\n",
    "import character_utility as charutil\n",
    "import config\n",
    "from ipywidgets_helper import render_images\n",
    "from kvg import Kvg\n",
    "from utility import pathstr, char2code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6009679",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class PreparedKvg():\n",
    "    root: Final[Kvg]\n",
    "    decomposition: Final[list[str]]\n",
    "    features: Final[dict[str, np.ndarray]]\n",
    "    images_for_sample: Final[dict[str, Image.Image]]\n",
    "\n",
    "\n",
    "def prepare_kvg(char: str, image_size: int, stroke_width: float, blur: float, log=False):\n",
    "    charcode = char2code(char)\n",
    "    directory_path = config.output_main_kvg_path(charcode)\n",
    "    with open(pathstr(directory_path, f\"{charcode}.json\")) as f:\n",
    "        root_kvg = Kvg.from_dict(json.load(f))\n",
    "\n",
    "    if log: print(json.dumps(root_kvg.to_dict(), ensure_ascii=False, indent=2))\n",
    "\n",
    "    kvgid2kvg: dict[str, Kvg] = {}\n",
    "    decompositions: dict[str, list[str]] = {}\n",
    "    def dfs(kvg: Kvg, is_root=True) -> list[Kvg]:\n",
    "        kvgid2kvg[kvg.kvgid] = kvg\n",
    "\n",
    "        # 小さすぎるなら分解しない\n",
    "        if not is_root:\n",
    "            image = Image.open(pathstr(\n",
    "                directory_path,\n",
    "                f\"{image_size}x,pad=0,sw={stroke_width} {kvg.kvgid}.png\",\n",
    "            ))\n",
    "            image = image.convert(\"1\")\n",
    "            image = np.array(image).transpose()\n",
    "            \n",
    "            nonzero_idx = image.nonzero()\n",
    "            nonzero_idx[0].sort()\n",
    "            nonzero_idx[1].sort()\n",
    "            \n",
    "            left = (nonzero_idx[0][0] - 1) / image.shape[0]\n",
    "            right = (nonzero_idx[0][-1]) / image.shape[0]\n",
    "            top = (nonzero_idx[1][0] - 1) / image.shape[1]\n",
    "            bottom = (nonzero_idx[1][-1]) / image.shape[1]\n",
    "\n",
    "            width = right - left\n",
    "            height = bottom - top\n",
    "\n",
    "            if width < 0.25 and height < 0.25:\n",
    "                return []\n",
    "            \n",
    "            if width * height < 0.125:\n",
    "                return []\n",
    "        \n",
    "        ret: list[Kvg] = []\n",
    "        if len(kvg.svg) == 0:\n",
    "            for kvg0 in kvg.children:\n",
    "                ret0 = dfs(kvg0, is_root=False)\n",
    "                if len(ret0) == 0:\n",
    "                    ret.clear()\n",
    "                    break\n",
    "                ret += ret0\n",
    "        \n",
    "        if len(ret):\n",
    "            decompositions[kvg.kvgid] = [kvg0.kvgid for kvg0 in ret]\n",
    "            return ret\n",
    "        \n",
    "        if kvg.name is None:\n",
    "            return []\n",
    "\n",
    "        ret = [kvg]\n",
    "        decompositions[kvg.kvgid] = [kvg0.kvgid for kvg0 in ret]\n",
    "        return ret\n",
    "    \n",
    "    dfs(root_kvg)\n",
    "\n",
    "    decomposition = decompositions[root_kvg.kvgid]\n",
    "\n",
    "    # root の分解に含まれていないものは削除\n",
    "    kvgid2kvg = {kvgid: kvg for kvgid, kvg in kvgid2kvg.items() if kvgid == root_kvg.kvgid or kvgid in decomposition}\n",
    "    decompositions = {kvgid: kvgids for kvgid, kvgids in decompositions.items() if kvgid == root_kvg.kvgid or kvgid in decomposition}\n",
    "\n",
    "    images_for_features: dict[str, Image.Image] = {}\n",
    "    features: dict[str, np.ndarray] = {}\n",
    "    images_for_sample: dict[str, Image.Image] = {}\n",
    "    for kvgid in decomposition:\n",
    "        images_for_features[kvgid] = Image.open(pathstr(\n",
    "            directory_path,\n",
    "            f\"{image_size}x,pad=0,sw={stroke_width} {kvgid}.png\",\n",
    "        ))\n",
    "        images_for_features[kvgid] = images_for_features[kvgid].filter(ImageFilter.GaussianBlur(blur))\n",
    "\n",
    "        features[kvgid] = np.array(images_for_features[kvgid])\n",
    "        features[kvgid] = np.concatenate((features[kvgid].reshape(-1), features[kvgid].transpose().reshape(-1))) # 一方向だけだと例えば「かんむり」と「たれ」が区別されにくい\n",
    "\n",
    "        images_for_sample[kvgid] = Image.open(pathstr(\n",
    "            directory_path,\n",
    "            f\"64x,pad=4,sw=2 {kvgid}.png\", # 雑\n",
    "        ))\n",
    "\n",
    "    pkvg = PreparedKvg(\n",
    "        root=root_kvg,\n",
    "        decomposition=decomposition,\n",
    "        features=features,\n",
    "        images_for_sample=images_for_sample,\n",
    "    )\n",
    "\n",
    "    return pkvg, kvgid2kvg, images_for_features, decompositions\n",
    "\n",
    "\n",
    "def test():\n",
    "    (\n",
    "        pkvg,\n",
    "        kvgid2kvg,\n",
    "        images_for_features,\n",
    "        decompositions,\n",
    "    ) = prepare_kvg(\"困\", image_size=16, stroke_width=2, blur=1, log=True)\n",
    "\n",
    "    print(f\"decompositions: {len(decompositions)}; {decompositions}\")\n",
    "\n",
    "    images = []\n",
    "    for kvgid, image in pkvg.images_for_sample.items():\n",
    "        images.append((image, kvgid))\n",
    "    for kvgid, image in images_for_features.items():\n",
    "        images.append((image, kvgid))\n",
    "    return render_images(images, columns=(len(images) // 2))\n",
    "\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ec7ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class KMeansResult:\n",
    "    kvgids: list[str]\n",
    "    features: np.ndarray\n",
    "    labels: list[int]\n",
    "    kmeans: KMeans\n",
    "\n",
    "\n",
    "def train_kmeans(pkvgs: list[PreparedKvg], kvgid2kvg: dict[str, Kvg], n_clusters, log=False, plot=False) -> KMeansResult:\n",
    "    kvgids: list[str] = []\n",
    "    features = []\n",
    "    for pkvg in pkvgs:\n",
    "        for kvgid, feature in pkvg.features.items():\n",
    "            kvgids.append(kvgid)\n",
    "            features.append(feature)\n",
    "    features = np.stack(features)\n",
    "\n",
    "    if log: print(f\"data size: {len(kvgids)}\")\n",
    "\n",
    "    kmeans = KMeans(n_init=4, n_clusters=n_clusters, init=\"k-means++\")\n",
    "    labels = kmeans.fit_predict(features).tolist()\n",
    "    \n",
    "    if plot:\n",
    "        pca = PCA(n_components=2)\n",
    "        boundings2d = pca.fit_transform(features)\n",
    "        print(f\"{pca.explained_variance_ratio_=}\")\n",
    "\n",
    "        plt.figure(figsize=(16, 16))\n",
    "        plt.scatter(boundings2d[:, 0], boundings2d[:, 1], c=labels)\n",
    "        for kvgid, xy in zip(kvgids, boundings2d):\n",
    "            kvg = kvgid2kvg[kvgid]\n",
    "            assert kvg.name is not None\n",
    "            plt.annotate(kvg.name, xy)\n",
    "    \n",
    "    return KMeansResult(kvgids=kvgids, features=features, labels=labels, kmeans=kmeans)\n",
    "\n",
    "\n",
    "def test(characters, n_clusters, image_size, stroke_width, blur):\n",
    "    pkvgs: list[PreparedKvg] = []\n",
    "    kvgid2kvg: dict[str, Kvg] = {}\n",
    "    for c in characters:\n",
    "        pkvg0, kvgid2kvg0, _, _ = prepare_kvg(c, image_size, stroke_width, blur)\n",
    "        pkvgs.append(pkvg0)\n",
    "        kvgid2kvg |= kvgid2kvg0\n",
    "\n",
    "    train_kmeans(pkvgs=pkvgs, kvgid2kvg=kvgid2kvg, n_clusters=n_clusters, log=True, plot=True)\n",
    "\n",
    "\n",
    "test(charutil.kanjis.education(), n_clusters=64, image_size=16, stroke_width=2, blur=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30777fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_elbow(characters, n_clusters_candidates, image_size, stroke_width, blur):\n",
    "    pkvgs: list[PreparedKvg] = []\n",
    "    kvgid2kvg: dict[str, Kvg] = {}\n",
    "    for c in characters:\n",
    "        pkvg0, kvgid2kvg0, _, _ = prepare_kvg(c, image_size, stroke_width, blur)\n",
    "        pkvgs.append(pkvg0)\n",
    "        kvgid2kvg |= kvgid2kvg0\n",
    "\n",
    "    distortions = []\n",
    "    for n_clusters in tqdm(n_clusters_candidates):\n",
    "        result = train_kmeans(pkvgs=pkvgs, kvgid2kvg=kvgid2kvg, n_clusters=n_clusters, log=False)\n",
    "        distortions.append(-result.kmeans.score(result.features))\n",
    "\n",
    "    plt.plot(n_clusters_candidates, distortions, marker=\"o\")\n",
    "    plt.xlabel(\"n_clusters\")\n",
    "    plt.ylabel(\"distortion\")\n",
    "\n",
    "\n",
    "plot_elbow(charutil.kanjis.all(), range(16, 512 + 1, 16), image_size=16, stroke_width=2, blur=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5985f164",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(characters, dataset_name, n_clusters, image_size, stroke_width, blur):\n",
    "    directory_path = config.output_radical_clustering_path(dataset_name, n_clusters, image_size, stroke_width, blur)\n",
    "    print(directory_path)\n",
    "    \n",
    "    os.makedirs(directory_path, exist_ok=False)\n",
    "    \n",
    "    pkvgs: list[PreparedKvg] = []\n",
    "    kvgid2kvg: dict[str, Kvg] = {}\n",
    "    decompositions: dict[str, list[str]] = {}\n",
    "    for c in characters:\n",
    "        pkvg0, kvgid2kvg0, _, decompositions0 = prepare_kvg(c, image_size, stroke_width, blur)\n",
    "        pkvgs.append(pkvg0)\n",
    "        kvgid2kvg |= kvgid2kvg0\n",
    "        decompositions |= decompositions0\n",
    "\n",
    "    with open(pathstr(directory_path, \"decompositions.json\"), \"w\") as f:\n",
    "        json.dump(decompositions, f)\n",
    "\n",
    "    result = train_kmeans(pkvgs=pkvgs, kvgid2kvg=kvgid2kvg, n_clusters=n_clusters, log=True)\n",
    "\n",
    "    with open(pathstr(directory_path, \"kmeans.pickle\"), \"wb\") as f:\n",
    "        pickle.dump(result.kmeans, f)\n",
    "\n",
    "    label2radicalname2kvgids: list[dict[str, list[str]]] = [{} for _ in range(n_clusters)]\n",
    "    for kvgid, label in zip(result.kvgids, result.labels):\n",
    "        kvg = kvgid2kvg[kvgid]\n",
    "\n",
    "        name = kvg.name\n",
    "        assert name is not None\n",
    "        if kvg.part is not None:\n",
    "            name = f\"{name}_{kvg.part}\"\n",
    "\n",
    "        label2radicalname2kvgids[label].setdefault(name, [])\n",
    "        label2radicalname2kvgids[label][name].append(kvg.kvgid)\n",
    "\n",
    "    for t in label2radicalname2kvgids:\n",
    "        for v in t.values():\n",
    "            v.sort()\n",
    "\n",
    "    with open(pathstr(directory_path, \"label2radicalname2kvgids.json\"), \"w\") as f:\n",
    "        json.dump(label2radicalname2kvgids, f)\n",
    "\n",
    "    def generate_result_html() -> str:\n",
    "        from base64 import b64encode\n",
    "        from io import BytesIO\n",
    "        from bs4 import BeautifulSoup\n",
    "\n",
    "        label2size = [0 for _ in range(n_clusters)]\n",
    "        for label in result.labels:\n",
    "            label2size[label] += 1\n",
    "\n",
    "        kvgid2sample_image: dict[str, Image.Image] = {}\n",
    "        for pkvg in pkvgs:\n",
    "            kvgid2sample_image |= pkvg.images_for_sample\n",
    "        \n",
    "        soup = BeautifulSoup(\"\", \"html.parser\")\n",
    "        \n",
    "        container = soup.new_tag(\"div\", style=\"display: flex; flex-direction: column; justify-content: center; gap: 2em\")\n",
    "        soup.append(container)\n",
    "\n",
    "        for label, (radicalname2kvgids, size, cluster_center) in enumerate(\n",
    "            zip(label2radicalname2kvgids, label2size, result.kmeans.cluster_centers_)\n",
    "        ):\n",
    "            cluster_el = soup.new_tag(\"div\", style=\"display: flex; flex-direction: column; gap: 1em\")\n",
    "            container.append(cluster_el)\n",
    "\n",
    "            title_el = soup.new_tag(\"div\")\n",
    "            title_el.string = f\"cluster: {label}, radicals: {size}\"\n",
    "            cluster_el.append(title_el)\n",
    "\n",
    "            images: list[tuple[str, Image.Image]] = []\n",
    "\n",
    "            center_image = (cluster_center[:(image_size ** 2)].reshape(image_size, image_size) + cluster_center[(image_size ** 2):].reshape(image_size, image_size).transpose()) / 2\n",
    "            center_image = Image.fromarray(center_image)\n",
    "            center_image = center_image.resize((image_size, image_size)).convert(\"L\")\n",
    "\n",
    "            images.append((\"center\", center_image))\n",
    "\n",
    "            for neg_num_kvgids, radical, image in sorted(tuple(\n",
    "                (-len(kvgids), radical, kvgid2sample_image[kvgids[0]])\n",
    "                for radical, kvgids in radicalname2kvgids.items()\n",
    "            )):\n",
    "                images.append((f\"{radical} × {-neg_num_kvgids}\", image))\n",
    "\n",
    "            image_container_el = soup.new_tag(\"div\", style=\"display: flex; gap: 1em\")\n",
    "            cluster_el.append(image_container_el)\n",
    "\n",
    "            for caption, image in images:\n",
    "                buffer = BytesIO()\n",
    "                image.save(buffer, \"png\")\n",
    "                base64 = b64encode(buffer.getvalue()).decode(\"ascii\")\n",
    "\n",
    "                figure_el = soup.new_tag(\"figure\", style=\"margin: 0; padding: 0; display: flex; flex-direction: column; align-items: center; gap: 0.5em\")\n",
    "                image_container_el.append(figure_el)\n",
    "\n",
    "                figcaption_el = soup.new_tag(\"figcaption\", style=\"line-height: 1\")\n",
    "                figcaption_el.string = caption\n",
    "                figure_el.append(figcaption_el)\n",
    "\n",
    "                img_el = soup.new_tag(\"img\", style=\"width: 64px; aspect-ratio: 1\", src=f\"data:image/png;base64,{base64}\")\n",
    "                figure_el.append(img_el)\n",
    "\n",
    "        return str(soup)\n",
    "    \n",
    "    html = generate_result_html()\n",
    "    with open(pathstr(directory_path, \"result.html\"), \"w\") as f:\n",
    "        print(html, file=f)\n",
    "\n",
    "    return IPython.display.HTML(html) # type: ignore\n",
    "\n",
    "\n",
    "# save(charutil.kanjis.jis_row(16), \"test\", n_clusters=16, image_size=16, stroke_width=2, blur=2)\n",
    "save(charutil.kanjis.all(), \"edu+jis_l1,2(new_decomp)\", n_clusters=384, image_size=16, stroke_width=2, blur=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
