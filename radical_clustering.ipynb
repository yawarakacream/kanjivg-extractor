{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5e52ea-955e-4807-bb14-3bd02de51587",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "from dataclasses import dataclass\n",
    "from typing import Final\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from PIL import Image, ImageFilter, ImageFont\n",
    "\n",
    "import character_utility as charutil\n",
    "import config\n",
    "from ipywidgets_helper import render_images\n",
    "from kvg import Kvg\n",
    "from utility import pathstr, char2code, create_vertical_stack_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class PreparedKvg():\n",
    "    root: Final[Kvg]\n",
    "    decomposition: Final[dict[str, Kvg]]\n",
    "    features: Final[dict[str, np.ndarray]]\n",
    "    images_for_sample: Final[dict[str, Image.Image]]\n",
    "\n",
    "\n",
    "def prepare_kvg(char: str, image_size: int, stroke_width: float, blur: float, log=False):\n",
    "    charcode = char2code(char)\n",
    "    directory_path = config.output_main_kvg_path(charcode)\n",
    "    with open(pathstr(directory_path, f\"{charcode}.json\")) as f:\n",
    "        root_kvg = Kvg.from_dict(json.load(f))\n",
    "    \n",
    "    if log: print(json.dumps(root_kvg.to_dict(), ensure_ascii=False, indent=2))\n",
    "\n",
    "    def dfs(kvg: Kvg) -> list[Kvg]:\n",
    "        ret: list[Kvg] = []\n",
    "        if len(kvg.svg) == 0:\n",
    "            for kvg0 in kvg.children:\n",
    "                ret0 = dfs(kvg0)\n",
    "                if len(ret0) == 0:\n",
    "                    ret.clear()\n",
    "                    break\n",
    "                ret += ret0\n",
    "        if len(ret) == 0:\n",
    "            if kvg.name is not None:\n",
    "                ret.append(kvg)\n",
    "\n",
    "        return ret\n",
    "\n",
    "    decomposition = {kvg.kvgid: kvg for kvg in dfs(root_kvg)}\n",
    "\n",
    "    images_for_features: dict[str, Image.Image] = {}\n",
    "    features: dict[str, np.ndarray] = {}\n",
    "    images_for_sample: dict[str, Image.Image] = {}\n",
    "    for kvgid in decomposition.keys():\n",
    "        images_for_features[kvgid] = Image.open(pathstr(\n",
    "            directory_path,\n",
    "            f\"{image_size}x,pad=0,sw={stroke_width} {kvgid}.png\",\n",
    "        ))\n",
    "        images_for_features[kvgid] = images_for_features[kvgid].filter(ImageFilter.GaussianBlur(blur))\n",
    "\n",
    "        features[kvgid] = np.array(images_for_features[kvgid])\n",
    "        features[kvgid] = np.concatenate((features[kvgid].reshape(-1), features[kvgid].transpose().reshape(-1))) # 一方向だけだと例えば「かんむり」と「たれ」が区別されにくい\n",
    "\n",
    "        images_for_sample[kvgid] = Image.open(pathstr(\n",
    "            directory_path,\n",
    "            f\"64x,pad=4,sw=2 {kvgid}.png\", # 雑\n",
    "        ))\n",
    "\n",
    "    pkvg = PreparedKvg(\n",
    "        root=root_kvg,\n",
    "        decomposition=decomposition,\n",
    "        features=features,\n",
    "        images_for_sample=images_for_sample,\n",
    "    )\n",
    "    return pkvg, images_for_features\n",
    "\n",
    "\n",
    "def test():\n",
    "    pkvg, images_for_features = prepare_kvg(\"遠\", image_size=16, stroke_width=2, blur=1, log=True)\n",
    "\n",
    "    images = []\n",
    "    for kvgid, image in pkvg.images_for_sample.items():\n",
    "        images.append((image, kvgid))\n",
    "    for kvgid, image in images_for_features.items():\n",
    "        images.append((image, kvgid))\n",
    "    return render_images(images, columns=(len(images) // 2))\n",
    "\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class KMeansResult:\n",
    "    kvgs: list[Kvg]\n",
    "    features: np.ndarray\n",
    "    labels: list[int]\n",
    "    kmeans: KMeans\n",
    "\n",
    "\n",
    "def train_kmeans(pkvgs: list[PreparedKvg], n_clusters, log=False, plot=False) -> KMeansResult:\n",
    "    kvgs: list[Kvg] = []\n",
    "    features = []\n",
    "    for pkvg in pkvgs:\n",
    "        for kvgid, feature in pkvg.features.items():\n",
    "            kvgs.append(pkvg.decomposition[kvgid])\n",
    "            features.append(feature)\n",
    "    features = np.stack(features)\n",
    "\n",
    "    if log: print(f\"data size: {len(kvgs)}\")\n",
    "\n",
    "    kmeans = KMeans(n_init=4, n_clusters=n_clusters, init=\"k-means++\")\n",
    "    labels = kmeans.fit_predict(features).tolist()\n",
    "    \n",
    "    if plot:\n",
    "        pca = PCA(n_components=2)\n",
    "        boundings2d = pca.fit_transform(features)\n",
    "        print(f\"{pca.explained_variance_ratio_=}\")\n",
    "\n",
    "        plt.figure(figsize=(16, 16))\n",
    "        plt.scatter(boundings2d[:, 0], boundings2d[:, 1], c=labels)\n",
    "        for kvg, xy in zip(kvgs, boundings2d):\n",
    "            assert kvg.name is not None\n",
    "            plt.annotate(kvg.name, xy)\n",
    "    \n",
    "    return KMeansResult(kvgs=kvgs, features=features, labels=labels, kmeans=kmeans)\n",
    "\n",
    "\n",
    "def test(characters, n_clusters, image_size, stroke_width, blur):\n",
    "    pkvgs = [prepare_kvg(c, image_size, stroke_width, blur)[0] for c in characters]\n",
    "    train_kmeans(pkvgs, n_clusters=n_clusters, log=True, plot=True)\n",
    "\n",
    "\n",
    "test(charutil.kanjis.education(), n_clusters=64, image_size=16, stroke_width=2, blur=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_elbow(characters, n_clusters_candidates, image_size, stroke_width, blur):\n",
    "    pkvgs = [prepare_kvg(c, image_size, stroke_width, blur)[0] for c in characters]\n",
    "\n",
    "    distortions = []\n",
    "    for n_clusters in tqdm(n_clusters_candidates):\n",
    "        result = train_kmeans(pkvgs, n_clusters=n_clusters, log=False)\n",
    "        distortions.append(-result.kmeans.score(result.features))\n",
    "\n",
    "    plt.plot(n_clusters_candidates, distortions, marker=\"o\")\n",
    "    plt.xlabel(\"n_clusters\")\n",
    "    plt.ylabel(\"distortion\")\n",
    "\n",
    "\n",
    "plot_elbow(charutil.kanjis.all(), range(16, 512 + 1, 16), image_size=16, stroke_width=2, blur=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(characters, dataset_name, n_clusters, image_size, stroke_width, blur, n_sample_images):\n",
    "    directory_path = config.output_radical_clustering_path(dataset_name, n_clusters, image_size, stroke_width, blur)\n",
    "    os.makedirs(directory_path, exist_ok=False)\n",
    "    \n",
    "    pkvgs = [prepare_kvg(c, image_size, stroke_width, blur)[0] for c in characters]\n",
    "    result = train_kmeans(pkvgs, n_clusters=n_clusters, log=True)\n",
    "\n",
    "    with open(pathstr(directory_path, \"kmeans.pickle\"), \"wb\") as f:\n",
    "        pickle.dump(result.kmeans, f)\n",
    "\n",
    "    # label2kvgids\n",
    "    label2kvgids = [[] for _ in range(n_clusters)]\n",
    "    for kvg, label in zip(result.kvgs, result.labels):\n",
    "        label2kvgids[label].append(kvg.kvgid)\n",
    "    for t in label2kvgids:\n",
    "        t.sort()\n",
    "\n",
    "    with open(pathstr(directory_path, \"label2kvgids.json\"), \"w\") as f:\n",
    "        json.dump(label2kvgids, f)\n",
    "\n",
    "    # cluster_samples_image\n",
    "    kvgid2label = {kvg.kvgid: label for kvg, label in zip(result.kvgs, result.labels)}\n",
    "\n",
    "    label2images: list[list[Image.Image]] = [[] for _ in range(n_clusters)]\n",
    "    for pkvg in pkvgs:\n",
    "        for kvgid, image in pkvg.images_for_sample.items():\n",
    "            label2images[kvgid2label[kvgid]].append(image)\n",
    "\n",
    "    n_clusters_digit = len(str(n_clusters))\n",
    "\n",
    "    image_data_list = []\n",
    "    for i in range(n_clusters):\n",
    "        center = result.kmeans.cluster_centers_[i]\n",
    "        center_image = (center[:(image_size ** 2)].reshape(image_size, image_size) + center[(image_size ** 2):].reshape(image_size, image_size).transpose()) / 2\n",
    "        center_image = Image.fromarray(center_image)\n",
    "        center_image = center_image.resize(label2images[i][0].size)\n",
    "\n",
    "        sample_images = label2images[i][:n_sample_images]\n",
    "\n",
    "        image_data_list.append(\"    \".join((f\"{str(i).zfill(n_clusters_digit)}\", f\"radicals: {len(label2images[i])}\")))\n",
    "        image_data_list.append([center_image, *sample_images])\n",
    "\n",
    "    cluster_samples_image = create_vertical_stack_image(\n",
    "        image_data_list,\n",
    "        gap=8,\n",
    "        font=ImageFont.truetype(config.font_path, size=24, index=0),\n",
    "    )\n",
    "    cluster_samples_image.save(pathstr(directory_path, \"cluster-samples.png\"))\n",
    "\n",
    "# save(charutil.kanjis.jis_row(16), \"test\", n_clusters=16, image_size=16, stroke_width=2, n_sample_images=16)\n",
    "save(charutil.kanjis.all(), \"edu+jis_l1,2\", n_clusters=512, image_size=16, stroke_width=2, blur=2, n_sample_images=16)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
